{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_learning_Resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhfKUmdetY9R",
        "colab_type": "text"
      },
      "source": [
        "#**CNN Model Training using Transfer Learning**\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzrvQI6yt0T0",
        "colab_type": "text"
      },
      "source": [
        "* Transfer learning is a method where knowledge gathered from one problem are used to solve similar or new problem.\n",
        "* Transfer learning is usually done for tasks where your dataset has too little data to train a full-scale model from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFv_dnbCuXeN",
        "colab_type": "text"
      },
      "source": [
        "***A. How to perform transfer learning?***\n",
        "1. Take layers from a previously trained model.\n",
        "2. Freeze all/some initial layers of the model.\n",
        "3. Add some new layers in the model.\n",
        "4. Train the new layers on new dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zuh2N9k1ujT7",
        "colab_type": "text"
      },
      "source": [
        "***B. How to perform fine-tuning?***\n",
        "1. Unfreezing the entire model \n",
        "2. Re-training it on the new data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thxhNPZxuZIS",
        "colab_type": "text"
      },
      "source": [
        "# Drive Mounting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJQp9bdGpnOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "0c6b7a73-134a-41e7-d892-333f6d76196a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmuN1Y10p9Ph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "98a975b4-7db4-4903-8e2d-ff42534d1a76"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/Colab\\ Notebooks/CVDL"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/CVDL'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdSE9ltEEfbg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b463e93e-8555-42a5-9aa2-7af6fe3e446e"
      },
      "source": [
        "!unzip rps-cv-images.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open rps-cv-images.zip, rps-cv-images.zip.zip or rps-cv-images.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIKN3iW7wGjU",
        "colab_type": "text"
      },
      "source": [
        "**Dividing the dataset into training, validation and test sets**\n",
        "\n",
        "To split the dataset we will use split-folders a python package under MIT license.\n",
        "\n",
        "Link: https://pypi.org/project/split-folders/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvjSmkg29I7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "eccc8703-e38a-466e-e866-0bd42bd8427a"
      },
      "source": [
        "!pip install split-folders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/4b/7b282b0f9319189d71e803220748929b37d019b67b1782d14c59cb1bd940/split_folders-0.4.2-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH4NW3nDQIdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import splitfolders   # or import split_folders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S93D1Hvi9fgn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a81cf854-acbb-41b0-abe6-148112ad3d10"
      },
      "source": [
        "input_folder='/content/drive/My Drive/Canvas/Day 1/rps-cv-images/rps-cv-images'\n",
        "# Split with a ratio.\n",
        "# To only split into training(80%), testing(10%), and validation(10%) set, using 'ratio' i.e (.8, .1, .1) \n",
        "splitfolders.ratio(input_folder, output=\"output\", seed=1337, ratio=(.8, .1, .1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying files: 2182 files [08:42,  4.17 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T5UOm8H3sys",
        "colab_type": "text"
      },
      "source": [
        "**Import necessary packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODc9VoA8AFoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "import glob\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_-S0RmHblxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdoeD2y434BD",
        "colab_type": "text"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjSgyg8V39BA",
        "colab_type": "text"
      },
      "source": [
        "Keras provides the ImageDataGenerator class for data preprocessing and data augmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og20oGk4lFw-",
        "colab_type": "text"
      },
      "source": [
        "1. rotation_range: Degree range for random rotations.\n",
        "2. horizontal_flip: Randomly flip inputs horizontally\n",
        "3. zoom_range: Range for random zoom.\n",
        "4. shear_range: Shear Intensity (Shear angle in counter-clockwise direction in degrees)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOU8Td51j6Y6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ce9d202b-dee1-4e51-f137-1d997fa3e3e8"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255\n",
        "                                   #horizontal_flip=True, vertical_flip=True, \n",
        "                                   #rotation_range=15,shear_range=15,\n",
        "                                   #zoom_range=0.15\n",
        "                                   )\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        \"output/train\",\n",
        "        target_size=(300, 200),\n",
        "        batch_size=64,\n",
        "        class_mode='categorical'\n",
        "        )\n",
        " \n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        'output/val',\n",
        "        target_size=(300, 200),\n",
        "        batch_size=64,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        'output/test',\n",
        "        target_size=(300, 200),\n",
        "        batch_size=64,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1745 images belonging to 3 classes.\n",
            "Found 217 images belonging to 3 classes.\n",
            "Found 220 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKcqEw7DgA6h",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Jqo3PXP41yz",
        "colab_type": "text"
      },
      "source": [
        "**A. Implementation of tranfer learning using keras:**\n",
        "\n",
        "1. Instantiate a base model and load pre-trained weights into it.\n",
        "2. Freeze all layers in the base model by setting trainable = False.\n",
        "3. Create a new model on top of the output of one (or several) layers from the base model.\n",
        "4. Train new model on new dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ulNAcmi3GcU",
        "colab_type": "text"
      },
      "source": [
        "**A.1 Loading the ResNet50 model with ImageNet pre-trained weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqayZubylzOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet = ResNet50(include_top=False, \n",
        "                   weights='imagenet', \n",
        "                   input_shape=(300, 200,3))\n",
        "#resnet.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3ANNHAm3SPa",
        "colab_type": "text"
      },
      "source": [
        "**A.2 Freeze all the layers of ResNet50**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0wnr8zC7pnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in resnet.layers[:-4]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkpwkXFNcCjY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be298cec-e74b-419c-f08c-f901ed54dec1"
      },
      "source": [
        "#resnet.trainable = False\n",
        "resnet.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 300, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 306, 206, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 150, 100, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 150, 100, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 150, 100, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 152, 102, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 75, 50, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 75, 50, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 75, 50, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 75, 50, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 75, 50, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 75, 50, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 75, 50, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 75, 50, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 75, 50, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 75, 50, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 75, 50, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 75, 50, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 75, 50, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 75, 50, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 75, 50, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 75, 50, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 75, 50, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 75, 50, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 75, 50, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 75, 50, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 75, 50, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 75, 50, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 75, 50, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 75, 50, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 75, 50, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 75, 50, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 75, 50, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 75, 50, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 75, 50, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 75, 50, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 75, 50, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 75, 50, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 75, 50, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 38, 25, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 38, 25, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 38, 25, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 38, 25, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 38, 25, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 38, 25, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 38, 25, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 38, 25, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 38, 25, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 38, 25, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 38, 25, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 38, 25, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 38, 25, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 38, 25, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 38, 25, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 38, 25, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 38, 25, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 38, 25, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 38, 25, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 38, 25, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 38, 25, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 38, 25, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 38, 25, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 38, 25, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 38, 25, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 38, 25, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 38, 25, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 38, 25, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 38, 25, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 38, 25, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 38, 25, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 38, 25, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 38, 25, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 38, 25, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 38, 25, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 38, 25, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 38, 25, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 38, 25, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 38, 25, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 38, 25, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 38, 25, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 38, 25, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 19, 13, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 19, 13, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 19, 13, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 19, 13, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 19, 13, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 19, 13, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 19, 13, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 19, 13, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 19, 13, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 19, 13, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 19, 13, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 19, 13, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 19, 13, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 19, 13, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 19, 13, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 19, 13, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 19, 13, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 19, 13, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 19, 13, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 19, 13, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 19, 13, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 19, 13, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 19, 13, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 19, 13, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 19, 13, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 19, 13, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 19, 13, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 19, 13, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 19, 13, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 19, 13, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 19, 13, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 19, 13, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 19, 13, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 19, 13, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 19, 13, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 19, 13, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 19, 13, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 19, 13, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 19, 13, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 19, 13, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 19, 13, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 19, 13, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 19, 13, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 19, 13, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 19, 13, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 19, 13, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 19, 13, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 19, 13, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 19, 13, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 19, 13, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 19, 13, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 19, 13, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 19, 13, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 19, 13, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 19, 13, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 19, 13, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 19, 13, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 19, 13, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 19, 13, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 19, 13, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 19, 13, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 19, 13, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 10, 7, 512)   524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 10, 7, 512)   2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 10, 7, 512)   0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 10, 7, 512)   2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 10, 7, 512)   2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 10, 7, 512)   0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 10, 7, 2048)  2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 10, 7, 2048)  1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 10, 7, 2048)  8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 10, 7, 2048)  8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 10, 7, 2048)  0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 10, 7, 2048)  0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 10, 7, 512)   1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 10, 7, 512)   2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 10, 7, 512)   0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 10, 7, 512)   2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 10, 7, 512)   2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 10, 7, 512)   0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 10, 7, 2048)  1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 10, 7, 2048)  8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 10, 7, 2048)  0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 10, 7, 2048)  0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 10, 7, 512)   1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 10, 7, 512)   2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 10, 7, 512)   0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 10, 7, 512)   2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 10, 7, 512)   2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 10, 7, 512)   0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 10, 7, 2048)  1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 10, 7, 2048)  8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 10, 7, 2048)  0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 10, 7, 2048)  0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 1,054,720\n",
            "Non-trainable params: 22,532,992\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScGlwUUlhgkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcHqUQ5M3jkA",
        "colab_type": "text"
      },
      "source": [
        "**A.3 Adding new layers to ResNet model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1Zr4fVqkan4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "68e6d960-cb44-4646-cb0d-da110754cb31"
      },
      "source": [
        "# Create the model\n",
        "model = models.Sequential()\n",
        "# Add the resnet convolutional base model\n",
        "model.add(resnet)\n",
        "\n",
        "# Add new layers\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(1024))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dense(512))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        " \n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 10, 7, 2048)       23587712  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 26,218,371\n",
            "Trainable params: 3,682,307\n",
            "Non-trainable params: 22,536,064\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XosXbT-L3tLc",
        "colab_type": "text"
      },
      "source": [
        "**A.4 Model Compilation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcOdiefNh0X7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkDfVRPg32uZ",
        "colab_type": "text"
      },
      "source": [
        "**A.5 Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2WfKaOrkMvE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aaeb61a0-cc0e-4046-a4bc-a502de58dfbe"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath='best_weights.hdf5'\n",
        "checkpointer=ModelCheckpoint(filepath,monitor='val_acc',mode='max',save_best_only=True,verbose=1)\n",
        "epochs = 20\n",
        "history=model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "        epochs=epochs,\n",
        "        callbacks=[checkpointer],\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_generator.samples//validation_generator.batch_size,\n",
        "        verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-21-77d1a16b9bd8>:12: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.4605 - acc: 0.8483\n",
            "Epoch 00001: val_acc improved from -inf to 0.25521, saving model to best_weights.hdf5\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.4605 - acc: 0.8483 - val_loss: 1.1203 - val_acc: 0.2552\n",
            "Epoch 2/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.1493 - acc: 0.9673\n",
            "Epoch 00002: val_acc did not improve from 0.25521\n",
            "27/27 [==============================] - 8s 289ms/step - loss: 0.1493 - acc: 0.9673 - val_loss: 1.1311 - val_acc: 0.2552\n",
            "Epoch 3/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0898 - acc: 0.9786\n",
            "Epoch 00003: val_acc improved from 0.25521 to 0.28125, saving model to best_weights.hdf5\n",
            "27/27 [==============================] - 8s 296ms/step - loss: 0.0898 - acc: 0.9786 - val_loss: 1.0990 - val_acc: 0.2812\n",
            "Epoch 4/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0632 - acc: 0.9917\n",
            "Epoch 00004: val_acc improved from 0.28125 to 0.39062, saving model to best_weights.hdf5\n",
            "27/27 [==============================] - 8s 302ms/step - loss: 0.0632 - acc: 0.9917 - val_loss: 1.0950 - val_acc: 0.3906\n",
            "Epoch 5/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0549 - acc: 0.9935\n",
            "Epoch 00005: val_acc did not improve from 0.39062\n",
            "27/27 [==============================] - 8s 283ms/step - loss: 0.0549 - acc: 0.9935 - val_loss: 1.0750 - val_acc: 0.3750\n",
            "Epoch 6/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0410 - acc: 0.9958\n",
            "Epoch 00006: val_acc did not improve from 0.39062\n",
            "27/27 [==============================] - 8s 287ms/step - loss: 0.0410 - acc: 0.9958 - val_loss: 1.0539 - val_acc: 0.3698\n",
            "Epoch 7/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0354 - acc: 0.9970\n",
            "Epoch 00007: val_acc did not improve from 0.39062\n",
            "27/27 [==============================] - 8s 283ms/step - loss: 0.0354 - acc: 0.9970 - val_loss: 1.0427 - val_acc: 0.3698\n",
            "Epoch 8/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0296 - acc: 0.9976\n",
            "Epoch 00008: val_acc did not improve from 0.39062\n",
            "27/27 [==============================] - 8s 283ms/step - loss: 0.0296 - acc: 0.9976 - val_loss: 1.0364 - val_acc: 0.3698\n",
            "Epoch 9/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0330 - acc: 0.9982\n",
            "Epoch 00009: val_acc did not improve from 0.39062\n",
            "27/27 [==============================] - 8s 285ms/step - loss: 0.0330 - acc: 0.9982 - val_loss: 1.0181 - val_acc: 0.3698\n",
            "Epoch 10/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0243 - acc: 1.0000\n",
            "Epoch 00010: val_acc did not improve from 0.39062\n",
            "27/27 [==============================] - 8s 286ms/step - loss: 0.0243 - acc: 1.0000 - val_loss: 1.0697 - val_acc: 0.3698\n",
            "Epoch 11/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0175 - acc: 1.0000\n",
            "Epoch 00011: val_acc did not improve from 0.39062\n",
            "27/27 [==============================] - 8s 285ms/step - loss: 0.0175 - acc: 1.0000 - val_loss: 1.0450 - val_acc: 0.3698\n",
            "Epoch 12/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0221 - acc: 0.9988\n",
            "Epoch 00012: val_acc improved from 0.39062 to 0.69792, saving model to best_weights.hdf5\n",
            "27/27 [==============================] - 8s 304ms/step - loss: 0.0221 - acc: 0.9988 - val_loss: 0.8764 - val_acc: 0.6979\n",
            "Epoch 13/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0177 - acc: 1.0000\n",
            "Epoch 00013: val_acc did not improve from 0.69792\n",
            "27/27 [==============================] - 8s 287ms/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.9485 - val_acc: 0.4062\n",
            "Epoch 14/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0152 - acc: 0.9994\n",
            "Epoch 00014: val_acc did not improve from 0.69792\n",
            "27/27 [==============================] - 8s 288ms/step - loss: 0.0152 - acc: 0.9994 - val_loss: 1.1575 - val_acc: 0.3698\n",
            "Epoch 15/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0146 - acc: 1.0000\n",
            "Epoch 00015: val_acc did not improve from 0.69792\n",
            "27/27 [==============================] - 8s 285ms/step - loss: 0.0146 - acc: 1.0000 - val_loss: 1.0590 - val_acc: 0.3854\n",
            "Epoch 16/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0112 - acc: 1.0000\n",
            "Epoch 00016: val_acc did not improve from 0.69792\n",
            "27/27 [==============================] - 8s 287ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.8489 - val_acc: 0.5469\n",
            "Epoch 17/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0107 - acc: 1.0000\n",
            "Epoch 00017: val_acc did not improve from 0.69792\n",
            "27/27 [==============================] - 8s 289ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 1.0531 - val_acc: 0.3802\n",
            "Epoch 18/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0178 - acc: 0.9970\n",
            "Epoch 00018: val_acc did not improve from 0.69792\n",
            "27/27 [==============================] - 8s 287ms/step - loss: 0.0178 - acc: 0.9970 - val_loss: 1.4306 - val_acc: 0.3958\n",
            "Epoch 19/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0119 - acc: 0.9994\n",
            "Epoch 00019: val_acc did not improve from 0.69792\n",
            "27/27 [==============================] - 8s 287ms/step - loss: 0.0119 - acc: 0.9994 - val_loss: 3.1276 - val_acc: 0.3750\n",
            "Epoch 20/20\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0111 - acc: 1.0000\n",
            "Epoch 00020: val_acc did not improve from 0.69792\n",
            "27/27 [==============================] - 8s 290ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.6142 - val_acc: 0.6875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwfI0RMS5i49",
        "colab_type": "text"
      },
      "source": [
        "**A.6 Testing the performance of the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cuMktRGkShj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ff9d3cf8-fefd-44fe-a799-e29724e15f05"
      },
      "source": [
        "model.load_weights(filepath)\n",
        "test_output= model.evaluate_generator(test_generator, steps=test_generator.samples/test_generator.batch_size, verbose=1)\n",
        "\n",
        "print(test_output)\n",
        "print(model.metrics_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/3 [==================================] - 1s 154ms/step - loss: 0.9851 - acc: 0.6136\n",
            "[0.9851409792900085, 0.6136363744735718]\n",
            "['loss', 'acc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp3korRw5nVC",
        "colab_type": "text"
      },
      "source": [
        "**A.7 Plotting the training accuracy and loss graph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In2FFW0zmgUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "303b56c8-2ed7-4bd6-f638-e5c908baed43"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3wU9bn48c+TC4kQLnKThIuAF1AEAgRQEYtVqyiCIlbQqhRv0FMveD9tFWrLObV6/FnrFW+oBwWrlaJCvWIBrZeAiIIQUOMxCAjhFkQgIc/vj+8sbJbdZJPs7mw2z/v1mtfMzszOPJndPPud73y/M6KqGGOMafjS/A7AGGNMbFhCN8aYFGEJ3RhjUoQldGOMSRGW0I0xJkVYQjfGmBRhCd2EJSLzReSyWK/rJxEpFpHT4rBdFZEjvelHROT2aNatw34uFpE36hpnNdsdJiIlsd6uSbwMvwMwsSMiO4NeNgX2APu811er6sxot6Wqw+OxbqpT1Ymx2I6IdAW+BjJVtcLb9kwg6s/QND6W0FOIquYEpkWkGLhCVd8KXU9EMgJJwhiTOqzKpREInFKLyK0isgF4SkQOFZFXRWSTiGz1pjsFveddEbnCmx4vIotF5B5v3a9FZHgd1+0mIgtFpExE3hKRB0XkfyPEHU2MfxCR97ztvSEibYOWXyIi34hIqYj8tprjM1hENohIetC880RkuTc9SET+LSLbRGS9iDwgIk0ibGuGiPwx6PXN3nu+E5EJIeueLSKfiMgOEflWRKYGLV7ojbeJyE4ROSFwbIPef6KIfCwi273xidEem+qIyDHe+7eJyAoRGRm07CwRWeltc52I3OTNb+t9PttEZIuILBIRyy8JZge88egAtAYOB67CffZPea+7AD8CD1Tz/sHAaqAt8GfgCRGROqz7HPAR0AaYClxSzT6jifEi4JdAe6AJEEgwxwIPe9vP8/bXiTBU9UPgB+CnIdt9zpveB0z2/p4TgFOBX1UTN14MZ3rxnA4cBYTW3/8AXAq0As4GJonIud6yk71xK1XNUdV/h2y7NfAacL/3t90LvCYibUL+hoOOTQ0xZwKvAG9477sGmCkiPbxVnsBV3zUHjgPe8ebfCJQA7YDDgN8Adl+RBLOE3nhUAlNUdY+q/qiqpar6kqruUtUyYBrwk2re/42qPqaq+4CngVzcP27U64pIF2AgcIeq7lXVxcDcSDuMMsanVLVIVX8EXgDyvfljgFdVdaGq7gFu945BJM8D4wBEpDlwljcPVV2iqh+oaoWqFgOPhokjnJ978X2uqj/gfsCC/753VfUzVa1U1eXe/qLZLrgfgDWq+qwX1/PAKuCcoHUiHZvqHA/kAH/yPqN3gFfxjg1QDhwrIi1UdauqLg2anwscrqrlqrpI7UZRCWcJvfHYpKq7Ay9EpKmIPOpVSezAneK3Cq52CLEhMKGqu7zJnFqumwdsCZoH8G2kgKOMcUPQ9K6gmPKCt+0l1NJI+8KVxkeLSBYwGliqqt94cRztVSds8OL4L1xpvSZVYgC+Cfn7BovIAq9KaTswMcrtBrb9Tci8b4COQa8jHZsaY1bV4B+/4O2ej/ux+0ZE/iUiJ3jz7wbWAm+IyFciclt0f4aJJUvojUdoaelGoAcwWFVbcOAUP1I1SiysB1qLSNOgeZ2rWb8+Ma4P3ra3zzaRVlbVlbjENZyq1S3gqm5WAUd5cfymLjHgqo2CPYc7Q+msqi2BR4K2W1Pp9jtcVVSwLsC6KOKqabudQ+q/929XVT9W1VG46pg5uJI/qlqmqjeqandgJHCDiJxaz1hMLVlCb7ya4+qkt3n1sVPivUOvxFsITBWRJl7p7pxq3lKfGF8ERojISd4FzDup+fv+HHAd7ofjbyFx7AB2ikhPYFKUMbwAjBeRY70flND4m+POWHaLyCDcD0nAJlwVUfcI254HHC0iF4lIhohcCByLqx6pjw9xpflbRCRTRIbhPqNZ3md2sYi0VNVy3DGpBBCRESJypHetZDvuukN1VVwmDiyhN173AYcAm4EPgH8maL8X4y4slgJ/BGbj2suHU+cYVXUF8B+4JL0e2Iq7aFedQB32O6q6OWj+TbhkWwY85sUcTQzzvb/hHVx1xDshq/wKuFNEyoA78Eq73nt34a4ZvOe1HDk+ZNulwAjcWUwpcAswIiTuWlPVvbgEPhx33B8CLlXVVd4qlwDFXtXTRNznCe6i71vATuDfwEOquqA+sZjaE7tuYfwkIrOBVaoa9zMEY1KdldBNQonIQBE5QkTSvGZ9o3B1scaYerKeoibROgB/x12gLAEmqeon/oZkTGqwKhdjjEkRVuVijDEpwrcql7Zt22rXrl392r0xxjRIS5Ys2ayq7cIt8y2hd+3alcLCQr92b4wxDZKIhPYQ3s+qXIwxJkVYQjfGmBRhCd0YY1JEUrVDLy8vp6SkhN27d9e8svFVdnY2nTp1IjMz0+9QjDGepEroJSUlNG/enK5duxL52QnGb6pKaWkpJSUldOvWze9wjDGepKpy2b17N23atLFknuREhDZt2tiZlDFJJqkSOmDJvIGwz8mY5JN0Cd0YY5LanDlQUtOdmP1hCT1IaWkp+fn55Ofn06FDBzp27Lj/9d69e6t9b2FhIddee22N+zjxxBNrXCca7777LiNGjIjJtowxUfrhBxg9Gv76V78jCSupLor6rU2bNixbtgyAqVOnkpOTw003HXhQekVFBRkZ4Q9ZQUEBBQUFNe7j/fffj02wxpjEW7MGVGFdfZ/0Fx9WQq/B+PHjmThxIoMHD+aWW27ho48+4oQTTqBfv36ceOKJrF69GqhaYp46dSoTJkxg2LBhdO/enfvvv3//9nJycvavP2zYMMaMGUPPnj25+OKLCdz5ct68efTs2ZMBAwZw7bXX1lgS37JlC+eeey59+vTh+OOPZ/ny5QD861//2n+G0a9fP8rKyli/fj0nn3wy+fn5HHfccSxatCjmx8yYlFVU5MbffedvHBEkbQn9+uvBKyzHTH4+3Hdf7d9XUlLC+++/T3p6Ojt27GDRokVkZGTw1ltv8Zvf/IaXXnrpoPesWrWKBQsWUFZWRo8ePZg0adJBbbY/+eQTVqxYQV5eHkOGDOG9996joKCAq6++moULF9KtWzfGjRtXY3xTpkyhX79+zJkzh3feeYdLL72UZcuWcc899/Dggw8yZMgQdu7cSXZ2NtOnT+eMM87gt7/9Lfv27WPXrl21PyDGNFaBhL5+vb9xRJC0CT2ZXHDBBaSnpwOwfft2LrvsMtasWYOIUF5eHvY9Z599NllZWWRlZdG+fXs2btxIp06dqqwzaNCg/fPy8/MpLi4mJyeH7t2772/fPW7cOKZPn15tfIsXL97/o/LTn/6U0tJSduzYwZAhQ7jhhhu4+OKLGT16NJ06dWLgwIFMmDCB8vJyzj33XPLz8+t1bIxpVBp6CV1EsoGFQJa3/ouhz38UkSzgGWAA7oG1F6pqcX0Cq0tJOl6aNWu2f/r222/nlFNO4eWXX6a4uJhhw4aFfU9WVtb+6fT0dCoqKuq0Tn3cdtttnH322cybN48hQ4bw+uuvc/LJJ7Nw4UJee+01xo8fzw033MCll14a0/0ak7ICCX3HDti5E7wq1GQRTR36HuCnqtoXyAfODH0COXA5sFVVjwT+H3BXbMNMHtu3b6djx44AzJgxI+bb79GjB1999RXFxcUAzJ5d8wPmhw4dysyZMwFXN9+2bVtatGjBl19+Se/evbn11lsZOHAgq1at4ptvvuGwww7jyiuv5IorrmDp0qUx/xuMSUmqsHo1tGjhXidhtUuNCV2dnd7LTG8IfW7dKOBpb/pF4FRJ0Z4nt9xyC//5n/9Jv379Yl6iBjjkkEN46KGHOPPMMxkwYADNmzenZcuW1b5n6tSpLFmyhD59+nDbbbfx9NPuo7jvvvs47rjj6NOnD5mZmQwfPpx3332Xvn370q9fP2bPns11110X87/BmJRUWgrbtsHQoe51EiZ0VLXGAUgHlgE7gbvCLP8c6BT0+kugbZj1rgIKgcIuXbpoqJUrVx40rzEqKytTVdXKykqdNGmS3nvvvT5HFJ59XqZRee89VVC9+243fv55X8IACjVCro6q2aKq7lPVfKATMEhEjqvjj8d0VS1Q1YJ27cI+QckAjz32GPn5+fTq1Yvt27dz9dVX+x2SMSZQf/6Tn7hxEl4YrVUrF1XdJiILgDNxpfKAdUBnoEREMoCWuIujpg4mT57M5MmT/Q7DGBNs9WrIyHDtn7Ozk7LKpcYSuoi0E5FW3vQhwOnAqpDV5gKXedNjgHe8UwNjjEkNRUVwxBGQmQl5eQ22hJ4LPC0i6bgfgBdU9VURuRNXlzMXeAJ4VkTWAluAsXGL2Bhj/FBUBEcf7aYbakJX1eVAvzDz7wia3g1cENvQjDEmSVRWuvu4nHGGe52bC59+6m9MYdi9XIwxpibffgt79kCPHu51Xl7DrENvTE455RRef/31KvPuu+8+Jk2aFPE9w4YNo7CwEICzzjqLbdu2HbTO1KlTueeee6rd95w5c1i5cuX+13fccQdvvfVWbcIPy26za0wMBFq4BFe5lJW5IYlYQg8ybtw4Zs2aVWXerFmzorpBFri7JLZq1apO+w5N6HfeeSennXZanbZljImxcAkdkq6Ubgk9yJgxY3jttdf2P8yiuLiY7777jqFDhzJp0iQKCgro1asXU6ZMCfv+rl27snnzZgCmTZvG0UcfzUknnbT/Frvg2pgPHDiQvn37cv7557Nr1y7ef/995s6dy80330x+fj5ffvkl48eP58UXXwTg7bffpl+/fvTu3ZsJEyawZ8+e/fubMmUK/fv3p3fv3qxaFdr4qCq7za4xdVRU5O7b0qGDe52b68ZJdmE0ee+26MP9c1u3bs2gQYOYP38+o0aNYtasWfz85z9HRJg2bRqtW7dm3759nHrqqSxfvpw+ffqE3c6SJUuYNWsWy5Yto6Kigv79+zNgwAAARo8ezZVXXgnA7373O5544gmuueYaRo4cyYgRIxgzZkyVbe3evZvx48fz9ttvc/TRR3PppZfy8MMPc/311wPQtm1bli5dykMPPcQ999zD448/HvHvs9vsGlNHgRYugTuaWAm9YQiudgmubnnhhRfo378//fr1Y8WKFVWqR0ItWrSI8847j6ZNm9KiRQtGjhy5f9nnn3/O0KFD6d27NzNnzmTFihXVxrN69Wq6devG0d6p3mWXXcbChQv3Lx89ejQAAwYM2H9Dr0gWL17MJZdcAoS/ze7999/Ptm3byMjIYODAgTz11FNMnTqVzz77jObNm1e7bWNSWnCTRTiQ0K2EHiWf7p87atQoJk+ezNKlS9m1axcDBgzg66+/5p577uHjjz/m0EMPZfz48ezevbtO2x8/fjxz5syhb9++zJgxg3fffbde8QZuwVuf2+/abXaNqcaePVBcDL/4xYF5LVrAIYckXUK3EnqInJwcTjnlFCZMmLC/dL5jxw6aNWtGy5Yt2bhxI/Pnz692GyeffDJz5szhxx9/pKysjFdeeWX/srKyMnJzcykvL99/y1uA5s2bUxbminmPHj0oLi5m7dq1ADz77LP8JHAviVqy2+waUwdffunaoQeX0EWSsuli8pbQfTRu3DjOO++8/VUvgdvN9uzZk86dOzNkyJBq39+/f38uvPBC+vbtS/v27Rk4cOD+ZX/4wx8YPHgw7dq1Y/DgwfuT+NixY7nyyiu5//77918MBcjOzuapp57iggsuoKKigoEDBzJx4sQ6/V2BZ5326dOHpk2bVrnN7oIFC0hLS6NXr14MHz6cWbNmcffdd5OZmUlOTg7PPPNMnfZpTIMX2sIlIAl7i4pft1wpKCjQQPvtgC+++IJjjjnGl3hM7dnnZRqFP/8Zbr3V3Qs9+NkEY8fC0qUHEn6CiMgSVS0It8yqXIwxpjpFRXDYYVWTObimi0lWQreEbowx1Qlt4RKQlwc//JBUvUWTLqHbXXcbBvucTKNRXUKHpCqlJ1VCz87OprS01JJFklNVSktLyc7O9jsUY+Jr+3bYuLHBJPSkauXSqVMnSkpK2LRpk9+hmBpkZ2fTqVMnv8MwJr7WrHHjcAk9Cbv/J1VCz8zMpFu3bn6HYYwxTqQmi5CU3f+TqsrFGGOSyurVrhPREUccvKx5c2jWLKlK6JbQjTEmkqIi6NoVvFtsVCGSdE0XLaEbY0wkkVq4BCRZ939L6MYYE46qS+iBx86Fk2Td/y2hG2NMOBs2wM6dNZfQv/vOJf8kYAndGGPCqa6FS0BuLuzaBTt2JCamGlhCN8aYcKJJ6EnWdLHGhC4inUVkgYisFJEVInJdmHWGich2EVnmDXfEJ1xjjEmQoiLXuqVz58jrJFlv0Wg6FlUAN6rqUhFpDiwRkTdVNfQZbItUdUTsQzTGGB8UFcFRR0FaNeXeJEvoNZbQVXW9qi71psuAL4CO8Q7MGGN8VVOTRTjQ/b+hVLkEE5GuQD/gwzCLTxCRT0Vkvoj0ivD+q0SkUEQK7X4txpikVVHhHj1XU0Jv3hxychpOCT1ARHKAl4DrVTX0ku5S4HBV7Qv8FZgTbhuqOl1VC1S1oF27dnWN2Rhj4qu4GMrLa07okFRt0aNK6CKSiUvmM1X176HLVXWHqu70pucBmSLSNqaRGmNMogRauFTXqSggibr/R9PKRYAngC9U9d4I63Tw1kNEBnnbLY1loMYYkzDRNFkMSKLu/9G0chkCXAJ8JiLLvHm/AboAqOojwBhgkohUAD8CY9WeUmGMaaiKiuDQQ6FNm5rXDe4t6sq1vqkxoavqYqDaKFX1AeCBWAVljDG+CrRwiSZB5+XBjz+6pxu1ahX/2KphPUWNMSZUNE0WA5LoyUWW0I0xJtiuXfDtt9En9CTq/m8J3Rhjgq1d68a1TehWQjfGmCRTmxYuYFUuxhiTtAIJ/cgjo1s/J8f1GLUqF2OMSTKrV0PHji5RRytJeotaQjfGmGA1PXYuHEvoxhiThGrTZDEgSbr/W0I3xpiA0lLYsqX2CT3Q/d/nDvKW0I0xJqC2LVwC8vJg927Yti32MdWCJXRjjAmoT0IH36tdLKEbY0xAURFkZEDXrrV7X5K0RbeEbowxAUVF0L07ZGbW7n1J0v3fEroxxgTUpYULWAndGGOSSmUlrFlTt4TerBm0bGkJ3RhjkkJJibuveV0SOrhSulW5GGNMEqjNc0TDSYLeopbQjTEG6t5kMcASujHGJImiIlcXHrjAWVuB7v8+9ha1hG6MMVC754iGk5cHe/fC1q2xjasWLKEbYwzUvcliQBL0FrWEbowxe/fC119bQjfGmAbvq69cO/T6JPQk6FxUY0IXkc4iskBEVorIChG5Lsw6IiL3i8haEVkuIv3jE64xxsRBfVu4wIGE7mNb9Iwo1qkAblTVpSLSHFgiIm+q6sqgdYYDR3nDYOBhb2yMMckvFgm9aVNo1Sq5S+iqul5Vl3rTZcAXQMeQ1UYBz6jzAdBKROrY9scYYxJs9Wpo394l5PrwuS16rerQRaQr0A/4MGRRR+DboNclHJz0EZGrRKRQRAo3bdpUu0iNMSZe6tvCJcDn7v9RJ3QRyQFeAq5X1R112ZmqTlfVAlUtaNeuXV02YYwxsRerhN4QSugikolL5jNV9e9hVlkHdA563cmbZ4wxyW3HDtiwIbYJ3afeotG0chHgCeALVb03wmpzgUu91i7HA9tV1d/bjhljTDTWrHHjWFW5lJe7h037IJpWLkOAS4DPRGSZN+83QBcAVX0EmAecBawFdgG/jH2oxhgTB7Fo4RIQ/OSitm3rv71aqjGhq+pioNqbG6iqAv8Rq6CMMSZhiorc/VuOOKL+2wruLdq7d/23V0vWU9QY07gVFcHhh0N2dv235XP3f0voxpjGLVYtXMD37v+W0I0xjZdqbBN6djYceqhvbdEtoRtjGq+NG12zxbo+di4cH9uiW0I3xjResWzhEmAJ3RhjfBCPhO5j939L6MaYxquoCLKyoHPnmteNVl6eS+iVlbHbZpQsoRtjGq+iIjjySEhPj9028/J86y1qCd0Y03jFsoVLgI9NFy2hG2Map337YO3a2Cf04O7/CWYJ3RjTOH3zjasaiVdCtxK6McYkSDxauIBVuRhjTMIFEnosOxWBazXTurUldGOMSZjVq90zRONxm9tA08UEs4RujGmcAi1cpNq7g9eNT71FLaEbYxqneDRZDLCEbowxCfLjj/B//xe/hJ6b655TmuDeopbQjTGNz9q1bhzPEnpFBWzeHJ/tR2AJ3RjT+MSryWKAT23RLaEbYxqfQEI/6qj4bN+ntuiW0I0xjU9RkStF5+TEZ/s+df+3hG6MaXzi2cIFoEMHN062ErqIPCki34vI5xGWDxOR7SKyzBvuiH2YxhgTQ0VFse8hGiwry3VYSnBCz4hinRnAA8Az1ayzSFVHxCQiY4yJpy1bXOuTeJbQwdWjJ1sJXVUXAlsSEIsxxsRfvFu4BPjQ/T9WdegniMinIjJfRHpFWklErhKRQhEp3LRpU4x2bYwxtZDIhJ5sJfQoLAUOV9W+wF+BOZFWVNXpqlqgqgXt2rWLwa6NMaaWiorcI+e6dYvvfvLyXG/Rffviu58g9U7oqrpDVXd60/OATBGJw+3LjDEmBoqKoHt3yMyM735yc10yT2Bv0XondBHpIOJuVyYig7xtJv7pqMYYE414N1kM8KG3aI2tXETkeWAY0FZESoApQCaAqj4CjAEmiUgF8CMwVlU1bhEbY0xd7dzpEvopp8R/X8EJvV+/+O+PKBK6qo6rYfkDuGaNxhiT3G65BXbvhgsvjP++fOj+bz1FjTGNwzvvwMMPw+TJcPzx8d9foLdoApsuWkI3xqS+sjKYMMHVnf/xj4nZZ5Mm0K5dctWhG2NMg3fzze6BFosXwyGHJG6/CW6LbiV0Y0xqe+stePRRuPFGOPHExO47wd3/LaEbY1LXjh1w+eXuRlx33pn4/Se4+79VuRhjUtdNN0FJCbz3XmKrWgKCe4ump8d9d1ZCN8akpjfegMcec0k9Ea1awsnLcw+K/v77hOzOEroxJvVs3w5XXAHHHAO//71/cQTaoieo2sUSujEm9dx4I6xbBzNmQHa2f3EkuPu/JXRjTGr55z/hiSdcr9BBg/yNxRK6McbU0bZtrqrl2GNh6lS/o4HDDgORhCV0a+VijEkdN9zgWpW8/LJ7rqffMjNdb1GrQzfGmFqYNw+eespVtQwc6Hc0BySwt6gldGNMw7d1K1x5JfTqBVOm+B1NVZbQjTGmFiZPho0b4emnk6OqJVhurlW5GGPi4Mcf4f774bXXoKLC72hi47XXXCK/7TYYMMDvaA6Wl+d+bBJwvO2iqDGNxbp1cO65UFjoXnfsCOPHu9vKdu/ua2h1Fqhq6d0bbr/d72jCC+4tGmjGGCcNL6Fv3eoeIfXDD9ENu3YdPK+iAjp1gq5d3ZO/g8edO0NGwzssxlTr449h1Ch3s6oXX4S0NHj8cfjv/4Zp0+DUU11zv3PP9bcjTm1dd51LlK++mnxVLQHBbdEtoYd44w0YOzbychFo1uzgoWlTaNPGTaenuxv2LFwIzz3nfj0D0tNdsg9N9IHpvLyE3GTHmJh5/nlXCu/QAf79b1eaBTjvPPd/MGOG64gzbhy0bg2/+IVL7oH1ktUrr8Czz7qSef/+fkcTWQK7/4tfz3MuKCjQwsCpX2189x0sW1Y1UQcn7uxsl9SjVV4O334LxcXw9ddVx8XFbn/Bxygz0yX17Gw3nZFR+6FJE/eP064dtG17YAi8zsmp3d9gTDiVlXDHHa4EPnQovPSS+45FWvedd1yp/eWXYe9e18vyiitcAap588TGXpMtW1yLlvbt3dlHkyZ+RxTZunWukPjII3D11fXenIgsUdWCcMsaXgk9Ly+2py2Zma7+MFId4p497kknwcm+pMR94Ssqwg+7dlV9XV5e9fWePe4LGekiSZMmVRN8aMIPTLdv78Zt2lg1kalq50645BKYM8cl5QcfrD7ppaXBaae5obQU/vd/3Z0Kr7rKtSC58EJ3X/ETTkiOwsa118Lmza7teTInc0hob9GGV0JPFaquPnPTJvfFDAzVvd66Nfy2RFyJP5Dgg5N96DjwA9BYqo0qKmDlSleKKyx0w+efu7Og3Nyah6ZN/f4Lau+bb2DkSPd33nuvS351ScKq8NFHrtQ+a5b7kTjmGPcDcdVV7hj64R//cHX9U6YkR/f+aHToAOec434k66m6Erol9IakosKVnjZtqjp8/33VcWB6y5aq1UXBgqupcnJqN92smbsAlZXlSkeBcfB08DhRPx779rkL5oWFBxL4smWuqR5AixZQUAB9+7qzqPXrDwwbNoQ/Y2rR4uAk37mzq2du2zYxf1dtLF4Mo0e7M8jZs+GMM2Kz3Z074YUXXHIP1MO/8gocfnhsth+tjz+Gs892Z+kffZT8pfOA/v1dzK++Wu9N1Suhi8iTwAjge1U9LsxyAf4CnAXsAsar6tKagrKEngChPwDBCX/nzqotf4Jfhy4LvmhcF2lpVZN8dja0auXOFFq3jm4c+o+rCl99VbXkvWSJix1cybp/f9cFvKDADUce6WIJp7LSHavgJL9+vTtNDp23e7c703n4YTj//Podm1h68kmYONFdwH/lFffYtXh44w34+c/dZ/LyyzBkSHz2E+qZZ9yZQW4uzJ8PPXsmZr+xMGKE+y4trTE11qi+degzgAeAZyIsHw4c5Q2DgYe9sfFbRoarvzvssLpvQ9UlsNDkv3evuxawd2/V6dBxuHm7d7vqo9JSWL3ajUtL3bWGSJo1O5DgmzVz1SiBKqisLMjPh8suc4l74ED3z16bM4O0tANVUn36VH88li93rUbGjHF1yw884G9pfd8+d/+Se+91deAvvACHHhq//f3sZ/Dhh64K4ac/henT3bGPl4oKuPlmuO8+OOUU9/cl49lRdfLyDrT/j6MaE7qqLhSRrtWsMgp4Rl1R/wMRaSUiuaqauCejmvgRcc9iPOSQ+P4Tqbofiy1bDiT4wHToeMcOl0wDybtXr8Sdeou4KpsPPoC77nIPHl6wwJXWR49OTAzBtm93rVD++U+45k0TnRIAABA+SURBVBqX1BNxgbxHD5fUL7jAdU5ascK1aY919VppqfvRfPtt1+b87rtdQ4aGJjfXnSFXVMT381HVGgegK/B5hGWvAicFvX4bKIiw7lVAIVDYpUsXNabB+/RT1X79VEF17FjVTZsSt++iItWePVUzMlQffTRx+w22d6/qr37l/v4RI1R37Ijdtj/9VLVbN9UmTVSfeip22/XDI4+4Y1RSUu9NAYUaIVcn9F4uqjpdVQtUtaBdpPawxjQkffq4kuqdd7p23r16uXrleHv7bRg82F0PefNNV7fsh8xM1yTywQddvfaJJ7qmvfX14ouuieSePa4D4Pjx9d+mnxL05KJYJPR1QOeg1528ecY0DpmZrrdiYaG7P8ro0XDRRa66INZ++MHVJZ9xxoGWHsOGxX4/tfWrX8Hrr7tONIMGwaJFddtOZSX87neuKqdvX3dMB6fAJbkGlNDnApeKczywXa3+3DRGgdL6738Pf/ubewxafUvrqvDFF65u/PTT3UXhyZNh+HB4//3kuqnWqae6v79NGzf95JO1e//27e5+M9OmuU5MCxYc6Dbf0CWq+3+kuhg9UO/9PLAeKAdKgMuBicBEb7kADwJfAp8Rof48dBgwYEC965KMSVrLlqnm57t604suUt28Ofr37typOneu6sSJqocf7rYBqscco3rDDapvvqm6b1/cQq+3rVtVTz/dxXzDDaoVFTW/Z9Uq1R493PWABx9UrayMf5yJVF6umpamevvt9d4U1dShR3VRNB6DJXST8vbuVf39712SOuww1Tlzwq9XWam6cqXq//yP6mmnuYuAoNqsmerIkaoPP6xaXJzY2OurvFz1mmvc33HWWarbt0de99VXVVu0UG3bVvXddxMXY6Ll5qpefnm9N2MJ3Rg/hSutRyqFH3us6o03qr71luru3X5HXn+PPOJ+0I49VvXLL6suq6xUnTZNVcS1FGpoP1q11b+/6vDh9d5MdQnduv4bkwjl5fBf/wV//KO7jcKuXa6TVU6Oq28ePhzOPDPxXekTYcEC16M2Lc21BPrJT9zF3V/+0l1rGDfO3VKgId43pzbOOcfd2O+TT+q1mdS626IxDVFmpruZVOCiX9euLomfdFLDuR9JXZ1yimuNc845rifrtGkwcyZ89hn8+c9w003JcQfHeAu0SoojS+jGJFJ+viuVNjZHHul61154Idx6q7uXz7x57qykscjLc71Fy8vj1tvVEroxJjFatnR3G5wxw5XajzjC74gSK9B0ceNG98CLOLCEboxJnIwMdz/1xii4c1GcEnpCu/4bY0yjlYDeopbQjTEmESyhG2NMimjXzjXdjGP3f0voxhiTCOnp7tmiVkI3xpgUkJdnCd0YY1JCbq4ldGOMSQl5eVaHbowxKSEvzz1lau/euGzeEroxxiRKoOnihg1x2bwldGOMSZQ4P7nIEroxxiRKnDsXWUI3xphEsYRujDEpol0718EoTgnd7rZojDGJkpYGjz4KffvGZfOW0I0xJpEuvzxum7YqF2OMSRGW0I0xJkVEldBF5EwRWS0ia0XktjDLx4vIJhFZ5g2N9JEkxhjjnxrr0EUkHXgQOB0oAT4WkbmqujJk1dmq+us4xGiMMSYK0ZTQBwFrVfUrVd0LzAJGxTcsY4wxtRVNQu8IfBv0usSbF+p8EVkuIi+KSOdwGxKRq0SkUEQKN23aVIdwjTHGRBKri6KvAF1VtQ/wJvB0uJVUdbqqFqhqQbt27eq0o1274IEHQLXuwRpjTCqKJqGvA4JL3J28efupaqmq7vFePg4MiE14B5s9G665Bv70p3jtwRhjGqZoEvrHwFEi0k1EmgBjgbnBK4hIbtDLkcAXsQuxqvHjYdw4+O1v4dVX47UXY4xpeGpM6KpaAfwaeB2XqF9Q1RUicqeIjPRWu1ZEVojIp8C1wPh4BSwCjz8O/frBRRfBF3H76TDGmIZF1KfK6IKCAi0sLKzz+//v/2DgQGjZEj76CFq1imFwxhiTpERkiaoWhFvWYHuKdukCL70ExcWupL5vn98RGWOMvxpsQgc46STX4mX+fFenbowxjVmDv9viVVfBJ5/AXXe5O1KOG+d3RMYY448GXUIP+MtfYOhQmDABlizxOxpjjPFHSiT0Jk3gxRfdw0DOOw++/97viIwxJvFSIqEDtG8Pc+bA5s0wZgzs3et3RMYYk1gpk9AB+veHJ56ARYvguuv8jsYYYxKrwV8UDTVuHHz66YGLpBMn+h2RMcYkRkqV0AOmTYPhw909XxYt8jsaY4xJjJRM6Onp8Nxz0L07nH++61VqjDGpLiUTOrhbAfzjH7Bnj2v5smuX3xEZY0x8pWxCB+jZE2bOdB2PrrjC7qFujEltKZ3QAUaMcHXqzz8Pd9/tdzTGGBM/KZ/QAW67DS680I3nzfM7GmOMiY9GkdBFXPv0vn3dnRmLivyOyBhjYq9RJHSAZs1cT9LMTFcNM306rFxp9erGmNTRaBI6wOGHu3uo79wJV18NvXq5+7+MGuXq1z/4wG4ZYIxpuFKup2hNTj4Z1q2DtWth8WLX8WjxYpjrPSU1OxsGD3b3Wh86FE44AVq08DdmY4yJRoN9BF2sbdwI7713IMl/8ol7ClJaGvTp45L7SSe5IS/P72iNMY1VdY+gs4Qewc6d8OGHBxL8v/99oHNSly7QrRt07OiGvLwD0x07Qm6uu6WvMcbEWnUJvdFVuUQrJwdOPdUNAOXl7qZfixe7h1KXlLg693XrXG/UUO3bV03ywck/N9ddpD3kEFfFExinNaorGsaYWLOEHqXMTCgocEMwVdiyxSX2cMO337rEv3lzzfto0qRqgg+eDh4fcgg0b+7q9lu2dOPQIXh+drZrummMSW1RJXQRORP4C5AOPK6qfwpZngU8AwwASoELVbU4tqEmJxFo08YNffpEXm/PHvjuO5fkN2xw1Te7d8OPP7px8HToODBdVubGgekdO8KfHYTKyKia6Js3h6ws9yPVpIkbAtPh5kVaHs0Qbv3MTKisdNcoKirCj2talpV14Mct9McuPT12n68xDUmNCV1E0oEHgdOBEuBjEZmrqiuDVrsc2KqqR4rIWOAu4MJ4BNxQZWW5evdu3WK73T17XGKPZti+3Y3Lytz7yspcM83ycjcOnQ683rcvtjHHW2bmwUk+NPFnZVUdmjSJbl5g/r597thUVFQd1zQvMJ2e7uLMyKjbOC3NbaOu48AZm0jV6XDzwi1PT3dDRkbVsZ/VhqruO7tnjxt27z4wHfo6Pb12hZDgY5bMoimhDwLWqupXACIyCxgFBCf0UcBUb/pF4AEREfXrimsjkpXl2tK3axe/fQSSV3WJv6YhdP20tIOTQeg40rK0NPdPGThbCZzBRPt627aq//ihQ2VlfI5jcFIOnHGUl6dW57bqkn3w5xpI/DX9mERaFvr57d4d3z4kIlUTfFrawXFVN4SuN3Ei3Hxz7OOMJqF3BL4Nel0CDI60jqpWiMh2oA0QRc2xSXaBf8LsbL8jSYx9+8In+uAkEihhhys9h5uuroRXWRm+ZB9pXF7u3hOotqrtOHDGpXrgxyR4HGk6eF5gO3WtNotm39UtC3f2lJ0d/owq3PzKyuoLHNUVSAI/+qGxRRrCrdOlS92+mzVJ6EVREbkKuAqgS7z+ImPqKT0dmjZ1QyKkpR1INMbURzQ1XuuAzkGvO3nzwq4jIhlAS9zF0SpUdbqqFqhqQbt41hEYY0wjFE1C/xg4SkS6iUgTYCwwN2SducBl3vQY4B2rPzfGmMSqscrFqxP/NfA6rtnik6q6QkTuBApVdS7wBPCsiKwFtuCSvjHGmASKqg5dVecB80Lm3RE0vRu4ILahGWOMqQ3rbG6MMSnCEroxxqQIS+jGGJMiLKEbY0yK8O1+6CKyCfimjm9vS3L3Qk32+CD5Y7T46sfiq59kju9wVQ3bkce3hF4fIlIY6QbvySDZ44Pkj9Hiqx+Lr36SPb5IrMrFGGNShCV0Y4xJEQ01oU/3O4AaJHt8kPwxWnz1Y/HVT7LHF1aDrEM3xhhzsIZaQjfGGBPCEroxxqSIpE7oInKmiKwWkbUicluY5VkiMttb/qGIdE1gbJ1FZIGIrBSRFSJyXZh1honIdhFZ5g13hNtWHGMsFpHPvH0XhlkuInK/d/yWi0j/BMbWI+i4LBORHSJyfcg6CT9+IvKkiHwvIp8HzWstIm+KyBpvfGiE917mrbNGRC4Lt06c4rtbRFZ5n+HLItIqwnur/T7EMb6pIrIu6HM8K8J7q/1/j2N8s4NiKxaRZRHeG/fjV2+qmpQD7la9XwLdgSbAp8CxIev8CnjEmx4LzE5gfLlAf2+6OVAUJr5hwKs+HsNioG01y88C5gMCHA986ONnvQHXYcLX4wecDPQHPg+a92fgNm/6NuCuMO9rDXzljQ/1pg9NUHw/AzK86bvCxRfN9yGO8U0FboriO1Dt/3u84gtZ/j/AHX4dv/oOyVxC3/9walXdCwQeTh1sFPC0N/0icKpIYp7NrarrVXWpN10GfIF7tmpDMgp4Rp0PgFYikutDHKcCX6pqXXsOx4yqLsTd0z9Y8PfsaeDcMG89A3hTVbeo6lbgTeDMRMSnqm+oaoX38gPcU8V8EeH4RSOa//d6qy4+L3f8HHg+1vtNlGRO6OEeTh2aMKs8nBoIPJw6obyqnn7Ah2EWnyAin4rIfBHpldDAQIE3RGSJ9zzXUNEc40QYS+R/Ij+PX8Bhqrrem94AHBZmnWQ5lhNwZ13h1PR9iKdfe1VCT0aoskqG4zcU2KiqayIs9/P4RSWZE3qDICI5wEvA9aq6I2TxUlw1Ql/gr8CcBId3kqr2B4YD/yEiJyd4/zXyHms4EvhbmMV+H7+DqDv3Tsq2viLyW6ACmBlhFb++Dw8DRwD5wHpctUYyGkf1pfOk/39K5oQes4dTx4uIZOKS+UxV/XvoclXdoao7vel5QKaItE1UfKq6zht/D7yMO60NFs0xjrfhwFJV3Ri6wO/jF2RjoCrKG38fZh1fj6WIjAdGABd7PzoHieL7EBequlFV96lqJfBYhP36ffwygNHA7Ejr+HX8aiOZE3pSP5zaq297AvhCVe+NsE6HQJ2+iAzCHe+E/OCISDMRaR6Yxl04+zxktbnApV5rl+OB7UFVC4kSsVTk5/ELEfw9uwz4R5h1Xgd+JiKHelUKP/PmxZ2InAncAoxU1V0R1onm+xCv+IKvy5wXYb/R/L/H02nAKlUtCbfQz+NXK35fla1uwLXCKMJd/f6tN+9O3BcXIBt3qr4W+AjonsDYTsKdei8HlnnDWcBEYKK3zq+BFbgr9h8AJyYwvu7efj/1Yggcv+D4BHjQO76fAQUJ/nyb4RJ0y6B5vh4/3I/LeqAcV497Oe66zNvAGuAtoLW3bgHweNB7J3jfxbXALxMY31pc/XPgexho+ZUHzKvu+5Cg+J71vl/LcUk6NzQ+7/VB/++JiM+bPyPwvQtaN+HHr76Ddf03xpgUkcxVLsYYY2rBEroxxqQIS+jGGJMiLKEbY0yKsIRujDEpwhK6McakCEvoxhiTIv4/gY5FXTUF8xMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31BdSRtulndN",
        "colab_type": "text"
      },
      "source": [
        "# FINE TUNING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mesDULPBTLn9",
        "colab_type": "text"
      },
      "source": [
        "**B.1 Loading the ResNet50 model with ImageNet pre-trained weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVRYDt8Imm6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c4f145f-f747-4c34-fa75-e470d989cd7d"
      },
      "source": [
        "new_base_model =keras.applications.ResNet50(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(224, 224,3)\n",
        ")\n",
        "new_base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnEIPOW7TQkW",
        "colab_type": "text"
      },
      "source": [
        "**B.2 Adding new layers to ResNet model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJU_jsHtmjHE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "e5b2518f-4141-404e-a1ab-51beebe93c1e"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        " \n",
        "# Create the model\n",
        "new_model = models.Sequential()\n",
        "# Add the resnet convolutional base model\n",
        "new_model.add(new_base_model)\n",
        "\n",
        "# Add new layers\n",
        "new_model.add(layers.GlobalAveragePooling2D())\n",
        "new_model.add(layers.Dense(1024))\n",
        "new_model.add(layers.BatchNormalization())\n",
        "new_model.add(layers.Activation('relu'))\n",
        "new_model.add(layers.Dense(512))\n",
        "new_model.add(layers.BatchNormalization())\n",
        "new_model.add(layers.Activation('relu'))\n",
        "\n",
        "new_model.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 26,218,371\n",
            "Trainable params: 26,162,179\n",
            "Non-trainable params: 56,192\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH2xaegLUWtb",
        "colab_type": "text"
      },
      "source": [
        "**B.3 Model Compilation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxQ69rArnuqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr3fwYu7UbEO",
        "colab_type": "text"
      },
      "source": [
        "**B.4 Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZPUx2hMpNS_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "0f711bdd-631a-436b-80ce-58372a4cf18a"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath='finetuning_best_weights.hdf5'\n",
        "checkpointer=ModelCheckpoint(filepath,monitor='val_acc',mode='max',save_best_only=True,verbose=1)\n",
        "epochs = 10\n",
        "new_history=new_model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "        epochs=epochs,\n",
        "        callbacks=[checkpointer],\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_generator.samples//validation_generator.batch_size,\n",
        "        verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 2/27 [=>............................] - ETA: 9s - loss: 0.6393 - acc: 0.6484WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2853s vs `on_train_batch_end` time: 0.4989s). Check your callbacks.\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.1558 - acc: 0.9459\n",
            "Epoch 00001: val_acc improved from -inf to 0.25521, saving model to finetuning_best_weights.hdf5\n",
            "27/27 [==============================] - 24s 892ms/step - loss: 0.1558 - acc: 0.9459 - val_loss: 8214.5713 - val_acc: 0.2552\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0239 - acc: 0.9923\n",
            "Epoch 00002: val_acc improved from 0.25521 to 0.37500, saving model to finetuning_best_weights.hdf5\n",
            "27/27 [==============================] - 23s 837ms/step - loss: 0.0239 - acc: 0.9923 - val_loss: 6.3088 - val_acc: 0.3750\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0543 - acc: 0.9875\n",
            "Epoch 00003: val_acc did not improve from 0.37500\n",
            "27/27 [==============================] - 22s 802ms/step - loss: 0.0543 - acc: 0.9875 - val_loss: 2.3784 - val_acc: 0.3750\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0371 - acc: 0.9863\n",
            "Epoch 00004: val_acc did not improve from 0.37500\n",
            "27/27 [==============================] - 22s 812ms/step - loss: 0.0371 - acc: 0.9863 - val_loss: 2.6293 - val_acc: 0.3750\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0209 - acc: 0.9935\n",
            "Epoch 00005: val_acc did not improve from 0.37500\n",
            "27/27 [==============================] - 22s 815ms/step - loss: 0.0209 - acc: 0.9935 - val_loss: 3.9135 - val_acc: 0.3750\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0253 - acc: 0.9935\n",
            "Epoch 00006: val_acc did not improve from 0.37500\n",
            "27/27 [==============================] - 22s 821ms/step - loss: 0.0253 - acc: 0.9935 - val_loss: 6.1468 - val_acc: 0.3750\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0148 - acc: 0.9964\n",
            "Epoch 00007: val_acc did not improve from 0.37500\n",
            "27/27 [==============================] - 22s 825ms/step - loss: 0.0148 - acc: 0.9964 - val_loss: 6.8878 - val_acc: 0.3750\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 00008: val_acc did not improve from 0.37500\n",
            "27/27 [==============================] - 22s 823ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 4.9401 - val_acc: 0.3750\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0017 - acc: 0.9994\n",
            "Epoch 00009: val_acc did not improve from 0.37500\n",
            "27/27 [==============================] - 22s 824ms/step - loss: 0.0017 - acc: 0.9994 - val_loss: 5.7385 - val_acc: 0.3750\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.0110 - acc: 0.9958\n",
            "Epoch 00010: val_acc did not improve from 0.37500\n",
            "27/27 [==============================] - 22s 827ms/step - loss: 0.0110 - acc: 0.9958 - val_loss: 5.6179 - val_acc: 0.3750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8snAFW5UlVK",
        "colab_type": "text"
      },
      "source": [
        "**B.5 Testing the performance of the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g575ytawpQiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1b1a733c-598a-4866-8393-a6f0b1647b24"
      },
      "source": [
        "new_model.load_weights(filepath)\n",
        "test_output= new_model.evaluate_generator(test_generator, steps=test_generator.samples/test_generator.batch_size, verbose=1)\n",
        "print(test_output)\n",
        "print(new_model.metrics_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/3 [==================================] - 1s 159ms/step - loss: 5.9794 - acc: 0.3318\n",
            "[5.979435920715332, 0.33181819319725037]\n",
            "['loss', 'acc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNpjv3VdUo9u",
        "colab_type": "text"
      },
      "source": [
        "**B.6 Plotting the training accuracy and loss graph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5pqLJDZpS7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "c9e5d8be-51db-4248-b1dd-11d4ecbebec3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = new_history.history['acc']\n",
        "val_acc = new_history.history['val_acc']\n",
        "loss = new_history.history['loss']\n",
        "val_loss = new_history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbc41xJ3VPyw",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "\n",
        "1. https://keras.io/guides/transfer_learning/\n",
        "\n",
        "2. https://pypi.org/project/split-folders/\n",
        "\n",
        "3. https://keras.io/api/applications/\n",
        "\n",
        "4. https://keras.io/api/preprocessing/image/"
      ]
    }
  ]
}